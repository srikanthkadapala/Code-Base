{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "import datetime as dt\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName(\"appName\").setMaster(\"local\")\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sc.textFile(\"hdfs://172.16.1.114:8020/user/hive/warehouse/workingDirectory/500000_Records.csv\",minPartitions = 4)\n",
    "#x=(sc.textFile(\"hdfs://172.16.1.114:8020/user/hive/warehouse/workingDirectory/500000_Records.csv\",minPartitions = 4).map(lambda x: x.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.take(2) # top N records \n",
    "x.getNumPartitions()  ## Number of Partitions\n",
    "#x.count() # counting the number of records or line in the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Func(lines):\n",
    "    lines = lines.lower()\n",
    "    lines = lines.split(',')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4130827"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatmapped = x.flatMap(lambda x: x.split(','))\n",
    "mapped =  flatmapped.map(lambda x:(x,1))\n",
    "grouped = mapped.groupByKey()\n",
    "group_feq = grouped.mapValues(sum).map(lambda x: (x[1],x[0])).sortByKey(False)\n",
    "#group_feq.take(100)\n",
    "distinct1 = mapped.distinct()\n",
    "distinct1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18500037"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatmapped = x.flatMap(lambda x: x.split(','))\n",
    "sample1 = flatmapped.sample(False,2000)\n",
    "sample1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', (5, 3)), ('a', (4, 2))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Joins \n",
    "a = sc.parallelize([('a',2),('b',3)])\n",
    "b = sc.parallelize([('a',4),('b',5),('c',6)])\n",
    "c = b.join(a)\n",
    "c.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249975000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd = sc.parallelize(range(1,50000))\n",
    "num_rdd.reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('a', 3), ('b', 2), ('d', 4), ('e', 5)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= [('a',1),('b',2),('a',3),('d',4),('e',5)]  \n",
    "\n",
    "sc.parallelize(test).sortByKey(True,1).collect()  ## arranges in asc or desc order the input shoule be keyvalue order by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (1, 7),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (3, 7),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (4, 6),\n",
       " (4, 7)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,2,3,4])\n",
    "rdd2 = sc.parallelize([4,5,6,7])\n",
    "\n",
    "rdd1.union(rdd2).collect()  # union \n",
    "rdd1.intersection(rdd2).collect() # intersection\n",
    "rdd1.subtract(rdd2).collect() # substract\n",
    "rdd1.cartesian(rdd2).collect()  # cartesian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
